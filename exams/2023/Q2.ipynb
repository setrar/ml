{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bd54696-d86e-480d-bd38-eedac485f479",
   "metadata": {},
   "source": [
    "## 2. Global overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0ac74a-a8c7-483c-810f-d5b4de9b3b92",
   "metadata": {},
   "source": [
    "(a) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb8c6fc-e778-4180-959e-fceee94f67bc",
   "metadata": {},
   "source": [
    "True. You train a logistic regressor. The model parameters $\\mathbf{w}$ are very large. This may be a symptom of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f49e725-ac32-49cd-81c7-c502fdaf6bb0",
   "metadata": {},
   "source": [
    "(b) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778372e4-87df-4cde-ab5f-60fd9ad728fd",
   "metadata": {},
   "source": [
    "&#x274C; False. You train a perceptron and obtain the following parameters $ b = 0, \\mathbf{w} = [1, -2]^T $. The test point $ \\mathbf{x} = [1, 1]^T $, $ y = 1 $ is not correctly classified.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2fcc99-91ba-40a1-a943-135f1d82245c",
   "metadata": {},
   "source": [
    "(c) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8b6beb-4f28-4e72-af7e-d58ee52a72fe",
   "metadata": {},
   "source": [
    "&#x274C; False. For the previous question, if the model used is a hard SVM, the values of the support vectors are not required to determine if the point is well classified.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63eeaab1-3855-46d5-a1c0-d2ce16f25765",
   "metadata": {},
   "source": [
    "`(d)` [$1/2$ point] ***True/False.*** Reducing the number of leaves in a tree increases the bias and reduces the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc66098-6b74-4ea9-b0b7-9f7fb5ebbf7c",
   "metadata": {},
   "source": [
    "&#x2705; True. Reducing the number of leaves in a tree increases the bias and reduces the variance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f4aed1-f350-49b6-b32d-fb60d98e6112",
   "metadata": {},
   "source": [
    "`(e)` [$1/2$ point] ***True/False.*** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aeb650a-5455-404b-a987-113a16b9746a",
   "metadata": {},
   "source": [
    "&#x2705; True. For the neural network below, it holds that:\n",
    "$ \\frac{\\partial L}{\\partial w_{21}^{(4)}} = 2(a_2 - y_2)a_2(1 - a_2)a_1^{(3)} $\n",
    "as long as $ L = \\| \\mathbf{a} - \\mathbf{y} \\|^2 $ and the final layer uses a sigmoid, $\\sigma(z)$, as activation function, i.e.,\n",
    "$ a_1 = \\sigma\\left(\\sum_j w_{1j}^{(3)} a_j^{(2)}\\right), \\quad a_2 = \\sigma\\left(\\sum_j w_{2j}^{(3)} a_j^{(2)}\\right). $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed38ade4-d19b-4ee9-9e5b-5e23fb8175d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
